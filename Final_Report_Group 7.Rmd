---
title: "MA 679 Final Report"
author: "Group 7"
date: "2021/5/4"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
library("dplyr")
library("caret")
library("purrr")
library("randomForest")
library("e1071")
library("pROC")
#Data import
data <- read_excel("Health Literacy Transformed Data.xlsx", 
           sheet = "Transformed")

guide <- read_excel("NCCN Guidelines.xlsx")
```

# Introduction

For doctors we met with are interested in bias contained in SEER data, so after have some initial exploration of SEER data, we decided to see whether there is bias between doctor's decision and the treatment guideline. The treatment guideline is based on TNM cancer stage, we only have information about AJCC cancer stage, which means we cannot match all cancer type with their guidelines. Therefore, we only chose cancer on Salivary Grand to do further exploration since its treatment matches well with the data.

# Data Processing

In the data processing step, we first selected all the Salivary Grand cancer. In the 'NCCN Guidelines' file, there is no treatment guideline information for stage 'IVC' and 'IVNOS' of cancer Salivary Grand. We removed observations of 'IVNOS' stage since there are only 6 observations and this amount is trivial compared with the whole dataset. As for the 'IVC' stage, according to the information provided in 'head-and-neck.pdf' page 87, there is no preferred treatment, and the treatment should be individualized based on patient characteristics. Thus, we removed all observations of 'IVC' stage because we could not decide whether the given therapy follows the guideline or not. Other than these two stages, based on the `NCCN Guidelines`, we found that only stage 'IVB' has different preferred number one therapy from others, its therapy1 is Radiation while other stages are recommended to have Surgery. Depending on this information, we create a binary column to indicate whether each individual is given treatment following the guideline or not, in this case '0' means the treatment does not follow the guideline, '1' means the treatment follows the guideline. Meanwhile, we replace all the blank space and symbols in column names for convenience.

Also we created some new variables based on the EDA:
1. Insurance2: This is a categorical variable with levels 0,1,2. We find that people in the "Insured" class have a lowest rate of being given treatment not following the guideline, while people in the "Uninsured" class have the highest rate of that. "1" indicates the "Insured" class, "2" indicates the "Uninsured" class, and "0" indicates all others.

2. Subsites2: This is a categorical variable with two levels 0 and 1. We find that in the subsite class "C08.1-Sublingual gland", all the observations are given treatment following the guideline. "1" indicates an individual is in this class, "0" indicates all others. 

The specific plots and other results from EDA will be shown in the next part.

Because we decided to use machine learning, we also separate the data into training data and test data, and guarantee that the proportion of 0 and 1 response in both two samples are similar.

```{r}
sali <- data %>% filter(Site == "Salivary Gland")

sali <- sali %>% filter(`AJCC 7 Stage` != "IVC" & `AJCC 7 Stage` != "IVNOS")

sali$follow <- 0

saliB <- sali %>% filter(`AJCC 7 Stage` != "IVB")
unique(saliB$`Surgery Decision`)

for(i in 1:nrow(sali)){
  if (sali[i,]$`AJCC 7 Stage` != "IVB"){
     if(sali[i,]$`Surgery Decision` != "Not recommended"){
       sali[i,]$follow = 1
     }
  } else{
    if(sali[i,]$`Surgery Decision` == "Not recommended" | sali[i,]$`Surgery Decision` == "Not recommended, contraindicated due to              other cond; autopsy only (1973-2002)") {
      sali[i,]$follow == 1
    }
  }
}



sali$Insurance2 <- ifelse(sali$Insurance == "Insured", 1, 0)
for(i in 1:nrow(sali)){
  if(sali$Insurance[i] == "Uninsured"){
    sali$Insurance2[i] <- 2
  }
}

ins2 <- sali %>% filter(Insurance == "Uninsured")

sali$Subsite2 <- ifelse(sali$Subsite == "C08.1-Sublingual gland", 1, 0)
```

```{r}
names(sali) <- gsub("\\s+", "_", names(sali))
names(sali) <- gsub("%_<", "Pct_Less_", names(sali))
names(sali) <- gsub("%_", "Pct_", names(sali))
names(sali) <- gsub("-", "_", names(sali))
names(sali) <- gsub("\\(|)", "", names(sali))
names(sali) <- gsub("\\?", "", names(sali))
```

```{r}
#surgery decision, performed, radiation,  chemo, Mets, subsite, ID.
trainsali <- sali[,-c(1,15,16,20:25)]
trainsali$follow <- as.factor(trainsali$follow)
trainsali$Sex <- as.factor(trainsali$Sex)
trainsali$Year_of_Diagnosis <- as.factor(trainsali$Year_of_Diagnosis)
trainsali$Race <- as.factor(trainsali$Race)
trainsali$Insurance <- as.factor(trainsali$Insurance)
trainsali$AJCC_7_Stage <- as.factor(trainsali$AJCC_7_Stage )
trainsali$SEER_Registry <- as.factor(trainsali$SEER_Registry)

set.seed(123)
getColUni <- function(x){
  length(unique(x))
} 
getSample <- function(data){
  repeat{
    sample <-createDataPartition(y=data$follow,p=0.7,list=FALSE)
    train <- data[sample, ] 
    # length(train$follow)-sum(train$follow==1)
    # test <- data[-sample, ]
    # length(test$follow)-sum(test$follow==1)
    dataCat <- select_if(data,negate(is.numeric))
    trainCat <- select_if(train,negate(is.numeric))
    if(all(rapply(dataCat, getColUni)[-c(1,ncol(dataCat))]== rapply(trainCat, getColUni)[-c(1,ncol(trainCat))])) break
  }
  return(sample)
}

sample <- getSample(trainsali)

train <- trainsali[sample,]
test <- trainsali[-sample,]
```

# EDA
This is a imbalanced dataset in terms of Race, Gender, SEER_Registry, and Insurance type. (plots)

Besides this , there are only 197 observations in class 0 while 2108 observations in class 1, so we also have extremely imbalanced classes in our outcome. (plots)


# Modeling
We tried the logistic regression and multilevel logistic regression as our baselines, and then we moved on to the classification tree, svm, and random forest.

## Random Forest

We first fitted a normal randomForest model.


Next, to deal with the imbalanced classes problem, we tried the stratified sampling method in randomForest with different ratios of class0 vs. class1, such as 1:100, 1:10, and 1:1, and it turns out that the model performance is the best with ratio 1:1.

```{r}
# tune: mtry, ntree, sampsize
# create tune grid
mtry <- seq(2, 7, 1)
ntree <- seq(300, 3000, 300)
tune_grid <- expand.grid(mtry=mtry, ntree=ntree)
auc_tune <- c()
# tune mtry, ntree
for(i in 1:nrow(tune_grid)){
  rf_tune <- randomForest(follow ~  Sex + Race + Year_of_Diagnosis + Age_at_Diagnosis + Insurance2 + Lymph_Nodes+ Subsite2 + AJCC_7_Stage, data = train, mtry = tune_grid$mtry[i], ntree = tune_grid$ntree[i])
  pred_tune <- predict(rf_tune, test, type = "class")
  auc_tune[i] <- roc.curve(test$follow, factor(pred_tune))$auc
}
mtry_best <- tune_grid[which.min(auc_tune),]$mtry
ntree_best <- tune_grid[which.min(auc_tune),]$ntree

# Fit random forest
rf = randomForest(follow ~  Sex + Race + Year_of_Diagnosis + Age_at_Diagnosis + Insurance2 + Lymph_Nodes+ Subsite2 + AJCC_7_Stage, data = train, mtry=mtry_best, ntree=ntree_best)
pred_forest = predict(rf, test, type = "class")
confusionMatrix(pred_forest, test$follow)
roc.curve(test$follow, factor(pred_forest))

# create tune grid for random forest with stratified sampling
sampsize <- round(nrow(train)*c(0.7, 0.8, 0.9))
tune2_grid <- expand.grid(mtry=mtry, ntree=ntree, sampsize=sampsize)
auc2_tune <- c()

for(i in 1:nrow(tune_grid)){
  rf2_tune <- randomForest(follow ~  Sex + Race + Year_of_Diagnosis + Age_at_Diagnosis + Insurance2 + Lymph_Nodes+ Subsite2 + AJCC_7_Stage, data = train, mtry = tune_grid$mtry[i], ntree = tune_grid$ntree[i], sampsize = tune_grid$sampsize[i])
  pred2_tune <- predict(rf2_tune, test, type = "class")
  auc2_tune[i] <- roc.curve(test$follow, factor(pred2_tune))$auc
}
mtry2_best <- tune_grid[which.min(auc2_tune),]$mtry
ntree2_best <- tune_grid[which.min(auc2_tune),]$ntree
sampsize2_best <- tune_grid[which.min(auc2_tune),]$sampsize

# random forest with stratified sampling
rf2 = randomForest(follow ~ Year_of_Diagnosis + Age_at_Diagnosis + Insurance2 + Lymph_Nodes + Subsite2 + AJCC_7_Stage + Sex + Race,
                   data = train, mtry = mtry2_best, ntree = ntree2_best, sampsize = sampsize2_best,strata = train$follow)
pred_forest2 = predict(rf2, test, type = "class")
confusionMatrix(pred_forest2, test$follow)
roc.curve(test$follow, factor(pred_forest2))
```
